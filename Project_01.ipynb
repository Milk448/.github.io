{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0zKscP7xBh4fArwjzxbYn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Milk448/.github.io/blob/master/Project_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "!pip install pymupdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh0rpTp4KXJf",
        "outputId": "84a81a55-9add-454c-86c1-8c80ca75b34d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.1\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.1-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- API Key Rotator (robust, cooldown-aware) ---\n",
        "import os\n",
        "import time\n",
        "from threading import Lock\n",
        "from dotenv import load_dotenv\n",
        "import google.generativeai as genai\n",
        "from PIL import Image\n",
        "import json\n",
        "import csv\n",
        "import re\n",
        "import logging\n",
        "import time\n",
        "import math\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "import google.generativeai as genai\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import fitz  # PyMuPDF\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fu4Jid7_KcME",
        "outputId": "15aab8da-f360-4074-9d1b-f5108e7ec87e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create the input directory if it doesn't exist\n",
        "input_dir = '/content/input'\n",
        "os.makedirs(input_dir, exist_ok=True)\n",
        "\n",
        "# Upload files\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move uploaded files to /content/input\n",
        "for filename in uploaded.keys():\n",
        "    os.rename(filename, os.path.join(input_dir, filename))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "ihowDP9rKgse",
        "outputId": "e664e413-3f0b-446f-f4b5-124f3b120fd3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-eaad1d5b-4a86-42e8-9a43-7910910fa908\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-eaad1d5b-4a86-42e8-9a43-7910910fa908\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hard and compelx Q&As_20.pdf to hard and compelx Q&As_20.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vBTIVLJJdM5",
        "outputId": "efb12cc5-d0ab-4d8b-ec0b-ab186bd34617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:No valid API keys found in GEMINI_API_KEYS. Please set it in Colab Secrets or environment.\n",
            "ERROR:root:Attempt 1 failed with error: cannot access local variable 'idx' where it is not associated with a value\n",
            "ERROR:root:Attempt 2 failed with error: cannot access local variable 'idx' where it is not associated with a value\n",
            "ERROR:root:Attempt 3 failed with error: cannot access local variable 'idx' where it is not associated with a value\n",
            "WARNING:root:All 3 attempts failed for hard and compelx Q&As_20_page_1.png.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "from threading import Lock\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import google.generativeai as genai\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "import json\n",
        "import csv\n",
        "import re\n",
        "import logging\n",
        "import math\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import fitz  # PyMuPDF\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - INFO: %(message)s',\n",
        "    handlers=[logging.StreamHandler()]\n",
        ")\n",
        "\n",
        "# Configuration\n",
        "SCRIPT_DIR = os.getcwd()\n",
        "INPUT_DIR = os.path.join(SCRIPT_DIR, \"input\")\n",
        "OUTPUT_DIR = os.path.join(SCRIPT_DIR, \"output\")\n",
        "RAW_OUTPUT = os.path.join(OUTPUT_DIR, \"raw_output\")\n",
        "TEMP_IMG_DIR = os.path.join(SCRIPT_DIR, \"temp_img\")\n",
        "OUTPUT_CSV = os.path.join(OUTPUT_DIR, \"output_results.csv\")\n",
        "OUTPUT_JSON = os.path.join(OUTPUT_DIR, \"output_results.json\")\n",
        "OUTPUT_PIPELINE_METRICS = os.path.join(OUTPUT_DIR, \"pipeline_metrics.png\")\n",
        "MAX_PROBLEMS = 100\n",
        "PDF_PAGE_SELECTION = \"all\"\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(INPUT_DIR, exist_ok=True)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(RAW_OUTPUT, exist_ok=True)\n",
        "os.makedirs(TEMP_IMG_DIR, exist_ok=True)\n",
        "\n",
        "# --- API Key Rotator ---\n",
        "class APIKeyRotator:\n",
        "    def __init__(self, env_var='GEMINI_API_KEYS', max_requests_per_minute=5, cooldown_seconds=300):\n",
        "        try:\n",
        "            keys = userdata.get(env_var).split(',')\n",
        "        except:\n",
        "            keys = os.getenv(env_var, '').split(',')\n",
        "        self.api_keys = [k.strip() for k in keys if k.strip()]\n",
        "        if not self.api_keys:\n",
        "            logging.error(\"No valid API keys found in GEMINI_API_KEYS. Please set it in Colab Secrets or environment.\")\n",
        "            exit(1)\n",
        "        self.max_requests = max_requests_per_minute\n",
        "        self.cooldown_seconds = cooldown_seconds\n",
        "        self.usage = [0] * len(self.api_keys)\n",
        "        self.timestamps = [time.time()] * len(self.api_keys)\n",
        "        self.cooldown = [0] * len(self.api_keys)\n",
        "        self.lock = Lock()\n",
        "        self.index = 0\n",
        "        logging.info(f\"Initialized APIKeyRotator with {len(self.api_keys)} keys: {[k[:5] + '...' for k in self.api_keys]}\")\n",
        "        self.validate_keys()\n",
        "\n",
        "    def validate_keys(self):\n",
        "        \"\"\"Validate each API key by making a test request.\"\"\"\n",
        "        for idx, key in enumerate(self.api_keys):\n",
        "            try:\n",
        "                genai.configure(api_key=key)\n",
        "                model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "                response = model.generate_content(\"Test prompt\")\n",
        "                logging.info(f\"API key {idx} is valid.\")\n",
        "            except Exception as e:\n",
        "                logging.warning(f\"API key {idx} may be invalid or rate-limited: {e}\")\n",
        "                self.mark_bad_key(idx, retry_after=300)\n",
        "\n",
        "    def get_key(self):\n",
        "        with self.lock:\n",
        "            now = time.time()\n",
        "            logging.info(f\"Checking {len(self.api_keys)} API keys. Usage: {self.usage}, Cooldowns: {[round(c - now, 2) for c in self.cooldown]}\")\n",
        "            for _ in range(len(self.api_keys)):\n",
        "                idx = self.index\n",
        "                if now - self.timestamps[idx] > 60:\n",
        "                    logging.info(f\"Resetting usage for key {idx}: {self.usage[idx]} -> 0\")\n",
        "                    self.usage[idx] = 0\n",
        "                    self.timestamps[idx] = now\n",
        "                if now < self.cooldown[idx]:\n",
        "                    logging.info(f\"Key {idx} in cooldown until {self.cooldown[idx]}\")\n",
        "                    self.index = (idx + 1) % len(self.api_keys)\n",
        "                    continue\n",
        "                if self.usage[idx] < self.max_requests:\n",
        "                    self.usage[idx] += 1\n",
        "                    logging.info(f\"Using key {idx} (usage: {self.usage[idx]}/{self.max_requests})\")\n",
        "                    self.index = (idx + 1) % len(self.api_keys)\n",
        "                    return self.api_keys[idx], idx\n",
        "                self.index = (idx + 1) % len(self.api_keys)\n",
        "            min_cooldown = min([c - now for c in self.cooldown if c > now], default=self.cooldown_seconds)\n",
        "            logging.info(f\"All keys in cooldown. Waiting {min_cooldown:.2f} seconds...\")\n",
        "            time.sleep(min_cooldown)\n",
        "            raise Exception(\"All API keys are in cooldown or over quota. Retrying after wait.\")\n",
        "\n",
        "    def mark_bad_key(self, idx, retry_after=None):\n",
        "        with self.lock:\n",
        "            cooldown_time = retry_after if retry_after else self.cooldown_seconds\n",
        "            self.cooldown[idx] = time.time() + cooldown_time\n",
        "            logging.info(f\"Marked key {idx} as bad. Cooldown until {self.cooldown[idx]} (duration: {cooldown_time}s)\")\n",
        "\n",
        "api_key_rotator = APIKeyRotator(max_requests_per_minute=5, cooldown_seconds=300)\n",
        "\n",
        "# --- Utility Functions ---\n",
        "def parse_page_selection(page_selection, max_pages):\n",
        "    \"\"\"Parse page selection string into list of page numbers (0-based).\"\"\"\n",
        "    if page_selection.lower() == \"all\":\n",
        "        return list(range(max_pages))\n",
        "    pages = set()\n",
        "    parts = page_selection.split(',')\n",
        "    for part in parts:\n",
        "        part = part.strip()\n",
        "        if not part:\n",
        "            continue\n",
        "        if '-' in part:\n",
        "            try:\n",
        "                start, end = map(int, part.split('-'))\n",
        "                pages.update(range(start - 1, end))\n",
        "            except ValueError:\n",
        "                logging.warning(f\"Invalid page range format: {part}. Skipping.\")\n",
        "        else:\n",
        "            try:\n",
        "                pages.add(int(part) - 1)\n",
        "            except ValueError:\n",
        "                logging.warning(f\"Invalid page number format: {part}. Skipping.\")\n",
        "    return sorted([p for p in pages if 0 <= p < max_pages])\n",
        "\n",
        "def clean_json_response(response_text: str) -> str:\n",
        "    \"\"\"Robust JSON cleaner for Gemini-2.0-flash output with complex LaTeX.\"\"\"\n",
        "    json_str = response_text.strip()\n",
        "    extraction_patterns = [\n",
        "        r'(?s)```json\\n(.*?)\\n```',\n",
        "        r'(?s)\\{(.*)\\}',\n",
        "        r'(?s)\"generated_question_llm1\":.*?\\}',\n",
        "        r'(?s)\\{(.*?)(?<!\\\\)\\}',\n",
        "    ]\n",
        "    for pattern in extraction_patterns:\n",
        "        try:\n",
        "            match = re.search(pattern, json_str)\n",
        "            if match:\n",
        "                json_str = match.group(1 if pattern == extraction_patterns[0] else 0).strip()\n",
        "                break\n",
        "        except:\n",
        "            continue\n",
        "    protected_patterns = [\n",
        "        (r'\\\\\\\\', r'ⓢⓢ'), (r'\\\\\"', r'ⓠ'), (r'\\\\/', r'ⓕ'), (r'\\\\b', r'ⓑ'),\n",
        "        (r'\\\\n', r'ⓝ'), (r'\\\\r', r'ⓡ'), (r'\\\\t', r'ⓣ')\n",
        "    ]\n",
        "    for pattern, replacement in protected_patterns:\n",
        "        json_str = re.sub(pattern, replacement, json_str)\n",
        "    json_str = re.sub(r'\\\\(?![ⓢⓠⓕⓑⓝⓡⓣ])', r'\\\\\\\\', json_str)\n",
        "    restoration_patterns = [\n",
        "        (r'ⓢⓢ', r'\\\\\\\\'), (r'ⓠ', r'\\\\\"'), (r'ⓕ', r'\\\\/'), (r'ⓑ', r'\\\\b'),\n",
        "        (r'ⓝ', r'\\\\n'), (r'ⓡ', r'\\\\r'), (r'ⓣ', r'\\\\t')\n",
        "    ]\n",
        "    for pattern, replacement in restoration_patterns:\n",
        "        json_str = json_str.replace(pattern, replacement)\n",
        "    math_modes = [\n",
        "        (r'\\\\\\(', r'ⓛⓟ'), (r'\\\\\\)', r'ⓛⓡ'), (r'\\\\\\[', r'ⓓⓛ'), (r'\\\\\\]', r'ⓓⓡ'),\n",
        "        (r'\\$\\$(.*?)\\$\\$', r'ⓓⓓ\\1ⓓⓓ'), (r'\\$(.*?)\\$', r'ⓘ\\1ⓘ')\n",
        "    ]\n",
        "    for pattern, replacement in math_modes:\n",
        "        json_str = re.sub(pattern, replacement, json_str)\n",
        "    json_str = re.sub(r',\\s*([}\\]])', r'\\1', json_str)\n",
        "    json_str = ''.join(char for char in json_str if ord(char) >= 32 or char in '\\t\\n\\r')\n",
        "    math_restore = [\n",
        "        (r'ⓛⓟ', r'\\\\('), (r'ⓛⓡ', r'\\\\)'), (r'ⓓⓛ', r'\\\\['), (r'ⓓⓡ', r'\\\\]'),\n",
        "        (r'ⓓⓓ(.*?)ⓓⓓ', r'$$\\1$$'), (r'ⓘ(.*?)ⓘ', r'$\\1$')\n",
        "    ]\n",
        "    for pattern, replacement in math_restore:\n",
        "        json_str = json_str.replace(pattern, replacement)\n",
        "    if not json_str.startswith('{'):\n",
        "        json_str = '{' + json_str\n",
        "    if not json_str.endswith('}'):\n",
        "        json_str += '}'\n",
        "    return json_str\n",
        "\n",
        "class ProblemVisualizer:\n",
        "    def __init__(self, output_dir):\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    def generate_metrics_chart(self, results):\n",
        "        \"\"\"Generates four subplots: processing status, evaluation accuracy, taxonomy success, and token usage.\"\"\"\n",
        "        valid_results = [r for r in results if isinstance(r, dict) and 'status' not in r]\n",
        "        if not valid_results:\n",
        "            logging.info(\"[!] No valid results to visualize.\")\n",
        "            return\n",
        "        image_filenames_for_labels = [r.get('image_filename', f\"Problem {i+1}\") for i, r in enumerate(results)]\n",
        "        success = [1 if isinstance(r, dict) and 'status' not in r else 0 for r in results]\n",
        "        failed = [1 if isinstance(r, dict) and 'status' in r else 0 for r in results]\n",
        "        correct = [1 if r.get('judge_evaluation') == \"Correct\" else 0 for r in valid_results]\n",
        "        incorrect = [1 if r.get('judge_evaluation') == \"Incorrect\" else 0 for r in valid_results]\n",
        "        total_evaluated = len(correct)\n",
        "        accuracy = (sum(correct) / total_evaluated * 100) if total_evaluated > 0 else 0\n",
        "        valid_subcategory = [1 if r.get('subcategory', 'N/A') != \"N/A\" else 0 for r in valid_results]\n",
        "        invalid_subcategory = [1 if r.get('subcategory', 'N/A') == \"N/A\" else 0 for r in valid_results]\n",
        "        prompt_tokens = [r.get('total_prompt_tokens_per_question', 0) for r in valid_results]\n",
        "        candidate_tokens = [r.get('total_candidate_tokens_per_question', 0) for r in valid_results]\n",
        "        successful_qnas = sum(success)\n",
        "        total_attempts = len(results)\n",
        "        success_rate = (successful_qnas / total_attempts * 100) if total_attempts > 0 else 0\n",
        "\n",
        "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
        "        x = np.arange(len(results))\n",
        "        width = 0.35\n",
        "        ax1.bar(x - width/2, success, width, label=f'Success ({success_rate:.1f}%)', color='#4CAF50')\n",
        "        ax1.bar(x + width/2, failed, width, label=f'Failed ({100 - success_rate:.1f}%)', color='#FF6B6B')\n",
        "        ax1.set_ylabel('Count')\n",
        "        ax1.set_title(f'Processing Status (Successful Q&As: {successful_qnas}/{total_attempts})')\n",
        "        ax1.legend()\n",
        "        ax1.set_xticks(x)\n",
        "        ax1.set_xticklabels(image_filenames_for_labels, rotation=45, ha='right')\n",
        "        ax1.set_ylim(0, 1.2)\n",
        "\n",
        "        x_valid = np.arange(len(valid_results))\n",
        "        ax2.bar(x_valid - width/2, correct, width, label='Correct', color='#4CAF50')\n",
        "        ax2.bar(x_valid + width/2, incorrect, width, label='Incorrect', color='#FF6B6B')\n",
        "        ax2.set_ylabel('Count')\n",
        "        ax2.set_title(f'Evaluation Accuracy ({accuracy:.1f}% Correct, {total_evaluated} Evaluated)')\n",
        "        ax2.legend()\n",
        "        ax2.set_xticks(x_valid)\n",
        "        ax2.set_xticklabels([r['image_filename'] for r in valid_results], rotation=45, ha='right')\n",
        "        ax2.set_ylim(0, max(max(correct + [0]), max(incorrect + [0])) + 0.2)\n",
        "\n",
        "        ax3.bar(x_valid - width/2, valid_subcategory, width, label='Valid Subcategory', color='#4CAF50')\n",
        "        ax3.bar(x_valid + width/2, invalid_subcategory, width, label='Invalid Subcategory (N/A)', color='#FF6B6B')\n",
        "        ax3.set_ylabel('Count')\n",
        "        ax3.set_title(f'Taxonomy Classification (Valid: {sum(valid_subcategory)}/{len(valid_results)})')\n",
        "        ax3.legend()\n",
        "        ax3.set_xticks(x_valid)\n",
        "        ax3.set_xticklabels([r['image_filename'] for r in valid_results], rotation=45, ha='right')\n",
        "        ax3.set_ylim(0, max(max(valid_subcategory + [0]), max(invalid_subcategory + [0])) + 0.2)\n",
        "\n",
        "        ax4.bar(x_valid - width/2, prompt_tokens, width, label='Prompt Tokens', color='#4CAF50')\n",
        "        ax4.bar(x_valid + width/2, candidate_tokens, width, label='Candidate Tokens', color='#0288D1')\n",
        "        ax4.set_ylabel('Tokens')\n",
        "        ax4.set_title('Token Usage per Problem')\n",
        "        ax4.legend()\n",
        "        ax4.set_xticks(x_valid)\n",
        "        ax4.set_xticklabels([r['image_filename'] for r in valid_results], rotation=45, ha='right')\n",
        "        ax4.set_ylim(bottom=0)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(OUTPUT_PIPELINE_METRICS, dpi=300)\n",
        "        plt.close()\n",
        "        logging.info(f\"Visualization saved to {OUTPUT_PIPELINE_METRICS}\")\n",
        "\n",
        "        total_prompt = sum(prompt_tokens)\n",
        "        total_candidate = sum(candidate_tokens)\n",
        "        total_api_time = sum(r.get('total_api_time_per_question', 0) for r in valid_results)\n",
        "        logging.info(\"\\nOverall Metrics for this Run:\")\n",
        "        logging.info(f\"  Total Prompt Tokens Used: {total_prompt}\")\n",
        "        logging.info(f\"  Total Candidate Tokens Generated: {total_candidate}\")\n",
        "        logging.info(f\"  Total API Time Spent: {total_api_time:.2f} seconds\")\n",
        "        logging.info(f\"  Success Rate: {success_rate:.1f}%\")\n",
        "        logging.info(f\"  Accuracy Rate (of evaluated problems): {accuracy:.1f}%\")\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    \"\"\"Preprocess the image to improve LaTeX extraction.\"\"\"\n",
        "    img = Image.open(image_path).convert('L')\n",
        "    enhancer = ImageEnhance.Contrast(img)\n",
        "    img = enhancer.enhance(2.0)\n",
        "    img = img.filter(ImageFilter.SHARPEN)\n",
        "    if max(img.size) > 800:\n",
        "        img = img.resize((int(img.size[0] * 0.7), int(img.size[1] * 0.7)), Image.LANCZOS)\n",
        "    return img\n",
        "\n",
        "def extract_latex_from_image(image_path, max_retries=3):\n",
        "    \"\"\"Extracts LaTeX from an image using Gemini Vision.\"\"\"\n",
        "    logging.info(f\"Attempting to extract LaTeX from {os.path.basename(image_path)} using Gemini Vision...\")\n",
        "    img = preprocess_image(image_path)\n",
        "    prompt = \"\"\"\n",
        "    Analyze this image for mathematical equations and formulas. Your output MUST:\n",
        "    - Identify and extract each distinct mathematical expression separately.\n",
        "    - Label each equation with 'Equation X:' where X is a number (e.g., Equation 1:, Equation 2:).\n",
        "    - Use $...$ for inline equations and $$...$$ for display equations.\n",
        "    - If no equations are found, return the raw text content of the image.\n",
        "    - Exclude markdown code blocks and include only the extracted content.\n",
        "    - Ensure correct LaTeX for special characters, fractions, integrals, etc.\n",
        "    - Place each labeled equation on a new line.\n",
        "    Example:\n",
        "    Equation 1: $ax^2 + bx + c = 0$\n",
        "    Equation 2: $$\\\\int_0^1 x^3 \\\\sqrt{1 - x^2} \\, dx = \\\\frac{2}{15}$$\n",
        "    \"\"\"\n",
        "    all_extracted_latex = []\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            response = call_gemini_with_rotation(prompt, img, model_name='gemini-2.0-flash', max_attempts=1)\n",
        "            end_time = time.time()\n",
        "            extracted_text = response.text.strip()\n",
        "            if extracted_text:\n",
        "                equations = []\n",
        "                current_equation = []\n",
        "                lines = extracted_text.split('\\n')\n",
        "                for line in lines:\n",
        "                    line = line.strip()\n",
        "                    if line.startswith(\"Equation\"):\n",
        "                        if current_equation:\n",
        "                            equations.append(\"\\n\".join(current_equation).strip())\n",
        "                        current_equation = [line]\n",
        "                    elif line and current_equation:\n",
        "                        current_equation.append(line)\n",
        "                if current_equation:\n",
        "                    equations.append(\"\\n\".join(current_equation).strip())\n",
        "                if equations:\n",
        "                    all_extracted_latex = equations\n",
        "                    logging.info(f\"Successfully extracted {len(equations)} LaTeX equations from {os.path.basename(image_path)} on attempt {attempt + 1}.\")\n",
        "                    return \"\\n\".join(equations), end_time - start_time\n",
        "                else:\n",
        "                    logging.warning(f\"Attempt {attempt + 1} failed: No valid equations segmented. Response: {extracted_text}\")\n",
        "                    return extracted_text, end_time - start_time\n",
        "            else:\n",
        "                logging.warning(f\"Attempt {attempt + 1} failed: No LaTeX extracted. Response: {response.text}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Attempt {attempt + 1} failed with error: {e}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                wait_time = 2 ** attempt\n",
        "                logging.info(f\"Retrying in {wait_time} seconds...\")\n",
        "                time.sleep(wait_time)\n",
        "    logging.warning(f\"All {max_retries} attempts failed for {os.path.basename(image_path)}.\")\n",
        "    debug_dir = os.path.join(TEMP_IMG_DIR, \"debug\")\n",
        "    os.makedirs(debug_dir, exist_ok=True)\n",
        "    debug_path = os.path.join(debug_dir, f\"failed_{os.path.basename(image_path)}\")\n",
        "    Image.open(image_path).save(debug_path)\n",
        "    logging.info(f\"Saved failed image to {debug_path} for debugging.\")\n",
        "    return \"No LaTeX found\", 0\n",
        "\n",
        "def extract_latex_from_pdf(pdf_path, page_selection=\"all\"):\n",
        "    \"\"\"Extracts LaTeX from PDF pages, converting to images.\"\"\"\n",
        "    logging.info(f\"Extracting LaTeX from PDF: {os.path.basename(pdf_path)} (pages: {page_selection})...\")\n",
        "    latex_expressions = []\n",
        "    try:\n",
        "        doc = fitz.open(pdf_path)\n",
        "        pages_to_process = parse_page_selection(page_selection, doc.page_count)\n",
        "        for i in pages_to_process:\n",
        "            if i >= doc.page_count:\n",
        "                logging.warning(f\"Page {i+1} is out of bounds for PDF {os.path.basename(pdf_path)}. Skipping.\")\n",
        "                continue\n",
        "            page = doc.load_page(i)\n",
        "            pix = page.get_pixmap()\n",
        "            img_filename = os.path.join(TEMP_IMG_DIR, f\"{Path(pdf_path).stem}_page_{i+1}.png\")\n",
        "            pix.save(img_filename)\n",
        "            logging.info(f\"Saved temporary image: {img_filename}\")\n",
        "            extracted_latex, api_time = extract_latex_from_image(img_filename)\n",
        "            if extracted_latex != \"No LaTeX found\":\n",
        "                equations = extracted_latex.split('\\n')\n",
        "                for eq_idx, eq in enumerate(equations, 1):\n",
        "                    if eq.strip().startswith(\"Equation\"):\n",
        "                        latex_expressions.append({\n",
        "                            \"page_number\": i + 1,\n",
        "                            \"image_path\": img_filename,\n",
        "                            \"latex\": eq.strip(),\n",
        "                            \"equation_number\": eq_idx,\n",
        "                            \"total_api_time_per_question\": api_time\n",
        "                        })\n",
        "            else:\n",
        "                latex_expressions.append({\n",
        "                    \"page_number\": i + 1,\n",
        "                    \"image_path\": img_filename,\n",
        "                    \"latex\": extracted_latex,\n",
        "                    \"total_api_time_per_question\": api_time\n",
        "                })\n",
        "        doc.close()\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error processing PDF {pdf_path}: {e}\")\n",
        "    return latex_expressions\n",
        "\n",
        "def compare_answers(answer1, answer2, rel_tol=1e-2):\n",
        "    \"\"\"Compare two answers with flexible comparison.\"\"\"\n",
        "    if answer1 == \"No answer found\" or answer2 == \"No answer found\":\n",
        "        return False\n",
        "    def unbox(ans):\n",
        "        box_match = re.search(r\"\\\\boxed\\{([^}]+)\\}\", ans)\n",
        "        return box_match.group(1) if box_match else ans\n",
        "    a1 = unbox(answer1).strip()\n",
        "    a2 = unbox(answer2).strip()\n",
        "    if a1 == a2:\n",
        "        return True\n",
        "    def to_float(ans_str):\n",
        "        try:\n",
        "            if '/' in ans_str and ans_str.count('/') == 1:\n",
        "                num_str, den_str = ans_str.split('/')\n",
        "                num = float(num_str.strip())\n",
        "                den = float(den_str.strip())\n",
        "                if den == 0: return None\n",
        "                return num / den\n",
        "            ans_str_cleaned = ans_str.lower().replace(' ', '')\n",
        "            if 'e' in ans_str_cleaned or 'x10^' in ans_str_cleaned or '*10^' in ans_str_cleaned:\n",
        "                ans_str_for_eval = ans_str_cleaned.replace('x10^', 'e').replace('*10^', 'e')\n",
        "                return float(ans_str_for_eval)\n",
        "            if ans_str_cleaned == 'pi': return math.pi\n",
        "            if ans_str_cleaned == 'e': return math.e\n",
        "            return float(ans_str.replace(',', ''))\n",
        "        except ValueError:\n",
        "            return None\n",
        "    val1 = to_float(a1)\n",
        "    val2 = to_float(a2)\n",
        "    if val1 is not None and val2 is not None:\n",
        "        return math.isclose(val1, val2, rel_tol=rel_tol)\n",
        "    return a1.lower() == a2.lower()\n",
        "\n",
        "def call_gemini_with_rotation(prompt, image_path, model_name='gemini-2.0-flash', max_attempts=5):\n",
        "    \"\"\"Call Gemini API with key rotation and retry logic.\"\"\"\n",
        "    last_exception = None\n",
        "    for attempt in range(max_attempts):\n",
        "        try:\n",
        "            api_key, idx = api_key_rotator.get_key()\n",
        "            genai.configure(api_key=api_key)\n",
        "            model = genai.GenerativeModel(model_name)\n",
        "            if isinstance(image_path, Image.Image):\n",
        "                response = model.generate_content([prompt, image_path])\n",
        "            else:\n",
        "                response = model.generate_content([prompt, Image.open(image_path)])\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            if \"429\" in str(e) or \"quota\" in str(e).lower():\n",
        "                retry_after = None\n",
        "                api_key_rotator.mark_bad_key(idx, retry_after)\n",
        "                last_exception = e\n",
        "                if attempt < max_attempts - 1:\n",
        "                    wait_time = 2 ** attempt\n",
        "                    logging.info(f\"Retrying in {wait_time} seconds...\")\n",
        "                    time.sleep(wait_time)\n",
        "                continue\n",
        "            else:\n",
        "                raise\n",
        "    raise Exception(f\"Failed after {max_attempts} attempts: {last_exception}\")\n",
        "\n",
        "def generate_problem_with_solutions(image_path, extracted_latex, max_attempts=5):\n",
        "    \"\"\"Generate STEM problem and solutions from LaTeX.\"\"\"\n",
        "    filename = os.path.basename(image_path)\n",
        "    if extracted_latex == \"No LaTeX found\" or not extracted_latex.strip():\n",
        "        return {\n",
        "            \"image_filename\": filename,\n",
        "            \"error\": \"No LaTeX extracted\",\n",
        "            \"status\": \"failed\"\n",
        "        }\n",
        "    start_time = time.time()\n",
        "    for attempt in range(max_attempts):\n",
        "        try:\n",
        "            if attempt < 2:\n",
        "                prompt = f\"\"\"\n",
        "                Given: {extracted_latex}\n",
        "                Generate a STEM problem in STRICT JSON format with:\n",
        "                - One PhD-level problem\n",
        "                - Two solution approaches\n",
        "                - Same final answer\n",
        "                - Proper LaTeX escaping (DOUBLE backslashes)\n",
        "                Output MUST be valid JSON with this EXACT structure:\n",
        "                {{\n",
        "                    \"q\": \"Problem statement\",\n",
        "                    \"s1\": \"Solution 1 steps\",\n",
        "                    \"a1\": \"\\\\boxed{{answer}}\",\n",
        "                    \"s2\": \"Solution 2 steps\",\n",
        "                    \"a2\": \"\\\\boxed{{same_answer}}\",\n",
        "                    \"cat\": \"Category\",\n",
        "                    \"sub\": \"Subcategory\"\n",
        "                }}\n",
        "                \"\"\"\n",
        "            else:\n",
        "                prompt = f\"\"\"\n",
        "                Given: {extracted_latex}\n",
        "                Output this EXACT JSON:\n",
        "                {{\n",
        "                    \"q\": \"Evaluate this expression\",\n",
        "                    \"s1\": \"Solution steps\",\n",
        "                    \"a1\": \"\\\\boxed{{result}}\",\n",
        "                    \"s2\": \"Same as above\",\n",
        "                    \"a2\": \"\\\\boxed{{result}}\",\n",
        "                    \"cat\": \"Math\",\n",
        "                    \"sub\": \"General\"\n",
        "                }}\n",
        "                \"\"\"\n",
        "            response = call_gemini_with_rotation(prompt, image_path, model_name='gemini-2.0-flash', max_attempts=1)\n",
        "            response_text = response.text\n",
        "            problem_data = None\n",
        "            for clean_attempt in range(3):\n",
        "                try:\n",
        "                    cleaned = clean_json_response(response_text)\n",
        "                    problem_data = json.loads(cleaned)\n",
        "                    if not all(k in problem_data for k in ['q', 's1', 'a1', 's2', 'a2']):\n",
        "                        raise ValueError(\"Missing required keys\")\n",
        "                    if not compare_answers(problem_data['a1'], problem_data['a2']):\n",
        "                        raise ValueError(\"Answer mismatch\")\n",
        "                    break\n",
        "                except Exception as e:\n",
        "                    if clean_attempt == 2:\n",
        "                        raise\n",
        "                    continue\n",
        "            end_time = time.time()\n",
        "            return {\n",
        "                \"image_filename\": filename,\n",
        "                \"extracted_latex\": extracted_latex,\n",
        "                \"generated_question_llm1\": problem_data['q'],\n",
        "                \"llm1_solution\": problem_data['s1'],\n",
        "                \"llm1_final_answer\": problem_data['a1'],\n",
        "                \"llm2_proposed_solution\": problem_data['s2'],\n",
        "                \"llm2_final_answer_extracted\": problem_data['a2'],\n",
        "                \"judge_evaluation\": \"Correct\",\n",
        "                \"api_answer_status\": \"yes\",\n",
        "                \"category\": problem_data.get('cat', 'Mathematics'),\n",
        "                \"subcategory\": problem_data.get('sub', 'General'),\n",
        "                \"total_api_time_per_question\": end_time - start_time,\n",
        "                \"total_prompt_tokens_per_question\": response.prompt_token_count if hasattr(response, 'prompt_token_count') else 0,\n",
        "                \"total_candidate_tokens_per_question\": response.candidate_token_count if hasattr(response, 'candidate_token_count') else 0\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logging.warning(f\"Attempt {attempt+1} failed: {str(e)[:100]}...\")\n",
        "            if attempt < max_attempts - 1:\n",
        "                time.sleep(2 ** attempt)\n",
        "            continue\n",
        "    return {\n",
        "        \"image_filename\": filename,\n",
        "        \"error\": f\"Failed after {max_attempts} attempts\",\n",
        "        \"status\": \"failed\"\n",
        "    }\n",
        "\n",
        "def get_input_files():\n",
        "    \"\"\"Gathers input files from INPUT_DIR, handling images and PDFs.\"\"\"\n",
        "    input_files = []\n",
        "    logging.info(f\"Scanning for input files in {INPUT_DIR}...\")\n",
        "    for root, _, files in os.walk(INPUT_DIR):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff')):\n",
        "                extracted_latex, api_time = extract_latex_from_image(file_path)\n",
        "                input_files.append({\n",
        "                    \"image_path\": file_path,\n",
        "                    \"latex\": extracted_latex,\n",
        "                    \"total_api_time_per_question\": api_time\n",
        "                })\n",
        "            elif file.lower().endswith('.pdf'):\n",
        "                logging.info(f\"Found PDF: {file_path}. Extracting pages as images...\")\n",
        "                extracted_pages = extract_latex_from_pdf(file_path, page_selection=PDF_PAGE_SELECTION)\n",
        "                input_files.extend(extracted_pages)\n",
        "            else:\n",
        "                logging.warning(f\"Skipping unsupported file type: {file_path}\")\n",
        "    if not input_files:\n",
        "        logging.warning(f\"No image or PDF files found in {INPUT_DIR}.\")\n",
        "    return sorted(input_files, key=lambda input_file: input_file['image_path'])\n",
        "\n",
        "def save_results(results):\n",
        "    \"\"\"Saves the processed results to CSV and JSON files.\"\"\"\n",
        "    if not results:\n",
        "        logging.warning(\"No results to save.\")\n",
        "        return\n",
        "    successful_results = [r for r in results if isinstance(r, dict) and 'status' not in r]\n",
        "    try:\n",
        "        with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, indent=4, ensure_ascii=False)\n",
        "        logging.info(f\"Results saved to {OUTPUT_JSON}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error saving results to JSON: {e}\")\n",
        "    if successful_results:\n",
        "        try:\n",
        "            fieldnames = list(successful_results[0].keys())\n",
        "            with open(OUTPUT_CSV, 'w', newline='', encoding='utf-8') as f:\n",
        "                writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "                writer.writeheader()\n",
        "                for row in successful_results:\n",
        "                    writer.writerow(row)\n",
        "            logging.info(f\"Results saved to {OUTPUT_CSV}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error saving results to CSV: {e}\")\n",
        "    else:\n",
        "        logging.warning(\"No successful results to save to CSV.\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to orchestrate the problem generation pipeline.\"\"\"\n",
        "    logging.info(\"Starting problem generation pipeline...\")\n",
        "    pipeline_start_time = time.time()\n",
        "\n",
        "    # Check API key cooldowns\n",
        "    now = time.time()\n",
        "    max_cooldown = max(api_key_rotator.cooldown, default=0)\n",
        "    if now < max_cooldown:\n",
        "        wait_time = max_cooldown - now\n",
        "        logging.info(f\"API keys in cooldown for {wait_time:.2f} seconds. Waiting...\")\n",
        "        time.sleep(wait_time)\n",
        "\n",
        "    input_files = get_input_files()\n",
        "    if not input_files:\n",
        "        logging.error(\"No input files found in the specified input directory.\")\n",
        "        return\n",
        "\n",
        "    results = []\n",
        "    files_to_process = input_files[:MAX_PROBLEMS]\n",
        "    logging.info(f\"Found {len(input_files)} input files. Processing up to {len(files_to_process)}.\")\n",
        "    max_workers = min(len(api_key_rotator.api_keys), 4)\n",
        "    logging.info(f\"Using {max_workers} workers for parallel processing.\")\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        future_to_file = {\n",
        "            executor.submit(generate_problem_with_solutions, file_info['image_path'], file_info['latex']): file_info\n",
        "            for file_info in files_to_process\n",
        "        }\n",
        "        for i, future in enumerate(as_completed(future_to_file), 1):\n",
        "            file_info = future_to_file[future]\n",
        "            logging.info(f\"[{i}/{len(files_to_process)}] Processing {os.path.basename(file_info['image_path'])}\")\n",
        "            try:\n",
        "                result = future.result()\n",
        "                results.append(result)\n",
        "                if 'status' not in result:\n",
        "                    logging.info(f\"  Generated problem: {result['generated_question_llm1'][:70]}...\")\n",
        "                    logging.info(f\"  LLM1 answer: {result['llm1_final_answer']}\")\n",
        "                    logging.info(f\"  LLM2 answer: {result['llm2_final_answer_extracted']}\")\n",
        "                    logging.info(f\"  Evaluation: {result['judge_evaluation']}\")\n",
        "                else:\n",
        "                    logging.warning(f\"  Failed to process {os.path.basename(file_info['image_path'])}: {result.get('error', 'Unknown error')}\")\n",
        "                # Add delay for single-key scenarios\n",
        "                if len(api_key_rotator.api_keys) == 1:\n",
        "                    time.sleep(12)  # 5 requests/min = 12s/request\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Exception for {os.path.basename(file_info['image_path'])}: {e}\")\n",
        "                results.append({\n",
        "                    \"image_filename\": os.path.basename(file_info['image_path']),\n",
        "                    \"error\": f\"Processing failed: {str(e)}\",\n",
        "                    \"status\": \"failed\"\n",
        "                })\n",
        "\n",
        "    if results:\n",
        "        save_results(results)\n",
        "        success_count = len([r for r in results if isinstance(r, dict) and 'status' not in r])\n",
        "        logging.info(f\"Pipeline finished. Successfully processed {success_count}/{len(results)} problems.\")\n",
        "        visualizer = ProblemVisualizer(OUTPUT_DIR)\n",
        "        visualizer.generate_metrics_chart(results)\n",
        "    else:\n",
        "        logging.warning(\"No valid results generated from any input file.\")\n",
        "\n",
        "    total_pipeline_time = time.time() - pipeline_start_time\n",
        "    logging.info(f\"Total pipeline execution time: {total_pipeline_time:.2f} seconds.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    start_time = time.time()\n",
        "    main()\n",
        "    end_time = time.time()\n",
        "    print(\"\\n\\n\\n\\n Total Time: \", end_time - start_time)"
      ]
    }
  ]
}